{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Xd5UXkyYeNQO"
   },
   "source": [
    "# CNN VAE for SRL for DIY Self driving car\n",
    "\n",
    "In this notebook, you will create the CNN VAE (beta) model. The resulting model is used as the state representation in reinforcement learning.\n",
    "\n",
    "Before running this, make sure you collect the training data using notebooks\\utility\\data_collection.ipynb. \n",
    "\n",
    "Collect images of the course while driving the car on the course. Collect 1k to 10k images. Adjust the number of data collected according to the size of the course. When running the course, run in the center of the course. During the trial during reinforcement learning, you do not know how to run on the course. Collect data so that the course can be represented in the event of an error.\n",
    "\n",
    "\n",
    "## Installing TensorBoardX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "!pip3 install tensorboardX # Updated to utilize Python 3"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0RgLaYFMeNQf"
   },
   "source": [
    "## Import module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jKObTxXVxUyT",
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import save_image\n",
    "from IPython.display import Image\n",
    "from IPython.core.display import Image, display\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wL75YrTqeNQi"
   },
   "source": [
    "## Load GPU device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "x1w9dHMDxc2t",
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iZXeMRs4eNQn"
   },
   "source": [
    "## Load dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "f8kgmDhAyVe8",
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "bs = 64\n",
    "dataset = datasets.ImageFolder(root='./dataset_root', transform=transforms.Compose([\n",
    "    torchvision.transforms.Resize((120, 160)),\n",
    "    torchvision.transforms.Lambda(lambda x: x.crop((0, 40, 160, 120))),\n",
    "    transforms.ToTensor(),\n",
    "]))\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=bs, shuffle=True,  num_workers=2, pin_memory=True)\n",
    "len(dataset.imgs), len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qxYHQhNKyX0q",
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "fixed_x, _ = next(iter(dataloader))\n",
    "save_image(fixed_x, 'real_image.png')\n",
    "Image('real_image.png')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EVLGbLF8yhy7"
   },
   "source": [
    "## Define VAE Network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tyFNicuqyj6s",
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "class Flatten(nn.Module):\n",
    "    def forward(self, input):\n",
    "        return input.view(input.size(0), -1)\n",
    "\n",
    "class UnFlatten(nn.Module):\n",
    "    def forward(self, input, size=256):\n",
    "        return input.view(input.size(0), size, 3, 8)\n",
    "\n",
    "\n",
    "class VAE(nn.Module):\n",
    "    def __init__(self, image_channels=3, h_dim=6144, z_dim=32):\n",
    "        super(VAE, self).__init__()\n",
    "        self.z_dim = z_dim\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(image_channels, 32, kernel_size=4, stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, kernel_size=4, stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 128, kernel_size=4, stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(128, 256, kernel_size=4, stride=2),\n",
    "            nn.ReLU(),\n",
    "            Flatten()\n",
    "        )\n",
    "\n",
    "        self.fc1 = nn.Linear(h_dim, z_dim)\n",
    "        self.fc2 = nn.Linear(h_dim, z_dim)\n",
    "        self.fc3 = nn.Linear(z_dim, h_dim)\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            UnFlatten(),\n",
    "            nn.ConvTranspose2d(256, 128, kernel_size=4, stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(64, 32, kernel_size=5, stride=2),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.out1 = nn.Sequential(nn.ConvTranspose2d(32, image_channels, kernel_size=4, stride=2),\n",
    "                                  nn.Sigmoid(),\n",
    "                                  )\n",
    "        self.out2 = nn.Sequential(nn.ConvTranspose2d(32, image_channels, kernel_size=4, stride=2),\n",
    "                                  nn.Sigmoid(),\n",
    "                                  )\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = logvar.mul(0.5).exp_()\n",
    "        esp = torch.randn(*mu.size()).to(device)\n",
    "        z = mu + std * esp\n",
    "        return z\n",
    "\n",
    "    def bottleneck(self, h):\n",
    "        mu, logvar = self.fc1(h), self.fc2(h)#F.softplus(self.fc2(h))\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        return z, mu, logvar\n",
    "\n",
    "    def encode(self, x):\n",
    "        h = self.encoder(x)\n",
    "        z, mu, logvar = self.bottleneck(h)\n",
    "        return z, mu, logvar\n",
    "\n",
    "    def decode(self, z):\n",
    "        z = self.fc3(z)\n",
    "        x = self.decoder(z)\n",
    "        mu_y = self.out1(x)\n",
    "        sigma_y = self.out2(x)\n",
    "        return mu_y, sigma_y\n",
    "\n",
    "    def forward(self, x):\n",
    "        z, mu, logvar = self.encode(x)\n",
    "        mu_y, sigma_y = self.decode(z)\n",
    "        return mu_y, sigma_y, mu, logvar\n",
    "\n",
    "    def loss_fn(self, image, mu_y, sigma_y, mean, logvar):\n",
    "        m_vae_loss = (mu_y - image)**2 /sigma_y\n",
    "        m_vae_loss = 0.5 * torch.sum(m_vae_loss)\n",
    "        a_vae_loss = torch.log(2.0 * torch.pi * sigma_y)\n",
    "        a_vae_loss = 0.5 * torch.sum(a_vae_loss)\n",
    "        KL = -0.5 * torch.sum((1 + logvar - mean.pow(2) - logvar.exp()), dim=0)\n",
    "        KL = torch.mean(KL)\n",
    "        return torch.mean((KL*5) + (10*m_vae_loss) +  a_vae_loss)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "v2wTqO-JyncH"
   },
   "source": [
    "## Prepare Training\n",
    "\n",
    "Install torch-summary. Torch-summary provides information complementary to what is provided by print(your_model) in PyTorch, similar to Tensorflow's model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "!pip3 install torch-summary"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create VAE model and initialize optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zDELfI7MUp2C",
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "from torchsummary import summary\n",
    "VARIANTS_SIZE = 32\n",
    "image_channels = fixed_x.size(1)\n",
    "vae = VAE(image_channels=image_channels, z_dim=VARIANTS_SIZE ).to(device)\n",
    "optimizer = torch.optim.Adam(vae.parameters(), lr=1e-3)\n",
    "summary(vae, (3, 80, 160))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "n73BXe26UsiP"
   },
   "source": [
    "## Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Hmvqsf_fw5Sp",
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir ./runs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ztKsDNhTU20H"
   },
   "source": [
    "## Start training\n",
    "\n",
    "Start training the model. Please note that this may take 30-45 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QVllkoOoU5c4",
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "from tensorboardX import SummaryWriter\n",
    "import numpy as np\n",
    "import math\n",
    "epochs = 100\n",
    "writer = SummaryWriter()\n",
    "\n",
    "vae.train()\n",
    "for epoch in range(epochs):\n",
    "    losses = []\n",
    "    grid = None\n",
    "    for idx, (images, _) in enumerate(dataloader):\n",
    "        images = images.to(device, non_blocking=True)\n",
    "        optimizer.zero_grad()\n",
    "        mu_y, sigma_y, mu, logvar = vae(images)\n",
    "        loss = vae.loss_fn(images, mu_y, sigma_y, mu, logvar)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        losses.append(loss.cpu().detach().numpy())\n",
    "        grid = torchvision.utils.make_grid(mu_y)\n",
    "        grid_sigma = torchvision.utils.make_grid(sigma_y)\n",
    "    writer.add_image('Image/reconst', grid, epoch)\n",
    "    writer.add_image('Image/sigma', grid_sigma, epoch)\n",
    "    writer.add_scalar('Loss/train',np.average(losses), epoch)\n",
    "    print(\"EPOCH: {} loss: {}\".format(epoch+1, np.average(losses)))\n",
    "\n",
    "torch.save(vae.state_dict(), 'vae.torch', _use_new_zipfile_serialization=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Visualize latent space\n",
    "Visualizing latent space by TensorBoard.\n",
    "You can visualize latent space with TensorBoard Projector view.\n",
    "The latent spaces are auto labeled by K-means. If similar images stick together, we consider the quality of the latent space to be good.\n",
    "\n",
    "First, we'll need to install all of the necessary packages.\n",
    "\n",
    "Note: If this section gives you issues, you can skip it. It is only for visualzation of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "!pip3 install scikit-learn # This may take 30+ minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "!pip3 install -U scipy # About 15-20 minutes to install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "!pip3 install -U numpy # About 10-15 minutes install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "!pip3 install -U pandas # 25-30 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "vae.eval()\n",
    "\n",
    "latent_spaces = None\n",
    "for idx,(images, _) in enumerate(dataloader):\n",
    "    images = images.to(device)\n",
    "    z, _, _ = vae.encode(images)\n",
    "    z = z.detach().cpu().numpy()\n",
    "    if latent_spaces is None:\n",
    "      latent_spaces = z.copy()\n",
    "    else:\n",
    "      latent_spaces = np.append(latent_spaces, z, axis=0)\n",
    "    if len(latent_spaces) > 5000:\n",
    "        break\n",
    "\n",
    "images, sigma_y = vae.decode(torch.Tensor(latent_spaces).to(device))\n",
    "images = F.interpolate(images, size=(40, 40), mode='bilinear', align_corners=False)\n",
    "\n",
    "kmeans_model = KMeans(n_clusters=5, verbose=0, n_init=10)\n",
    "labels = kmeans_model.fit_predict(latent_spaces)\n",
    "\n",
    "writer.add_embedding(mat=latent_spaces, metadata=labels, label_img=images)\n",
    "writer.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Re-launch TensorBoard\n",
    "This cell do kill tensorboard process and re-launch TensorBoardX. When do not show projector tab, click reload button."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "!kill $(ps | grep tensorboard | cut -f 1 -d '?')\n",
    "%tensorboard --logdir ./runs"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "VAE-CNN.ipynb のコピー",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
